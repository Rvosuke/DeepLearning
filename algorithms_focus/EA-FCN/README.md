# EA-FCN
## 人脑神经元
是构成大脑的基本单元,其结构和工作方式概括如下:
1. 结构:
- 树突 - 从细胞体延伸出的短突起,用于接收来自其他神经元的信号。
- 细胞体 - 神经元的主体,含有细胞核和其他细胞器。
- 轴突 - 从细胞体延伸出的长突起,将信号传递给其他神经元或效应器官。
- 轴突末梢 - 轴突的末端,含有突触小泡,分泌神经递质。

2. 工作方式:
- 静息电位 - 未受刺激时,神经元内外的离子浓度差形成静息电位。
- 接收信号 - 树突接收其他神经元释放的神经递质,导致膜电位变化。
- 兴奋 - 当膜电位达到**阈值**时,触发动作电位,信号沿轴突传递。
- 传递信号 - 动作电位到达轴突末梢后,引起神经递质释放,传递至下一个神经元或效应器。
- 突触可塑性 - 神经元间突触连接的效能可根据活动模式发生长期的增强或减弱。

"兴奋"时候存在一个阈值,此时才会进行信号传递,我不确定当前的人工智能神经网络构建中是否注意到了这一点.

## 多层感知机(MLP)

又称为"全连接层(FCN)",FCN的设计十分巧妙地模拟了神经元的工作方式.但是仍然有不足之处:FCN中的神经元信息传递依赖于边权重$W$,而在我看来这种设计只是在模拟各个神经元之间的链接关系,并没有真正达到"兴奋"的原有机理.

FCN的设计公式如下:
$$
F = WX+B.
$$
为了能够真正模拟"兴奋",我认为应该添加如下逻辑:
$$
F >= P, Activate F,
$$
这里P表示一个阈值,当F大于等于P时,激活F.

实际上,之前大名鼎鼎的Dropout就曾经模拟过这种思路,但是其随机暂退可解释性不高.而此时设置可训练的阈值进行"Dropout",可能会获得更好的效果.

## 兴奋

兴奋的训练并非易事,传统的FCN是通过反向传播来进行参数更新,而P是一个相对独立的值,并没有在所谓的"传播图"中.

既然P是一个离散的值,我考虑到了使用进化算法(EA)来完成优化.

当然具体采用什么样的进化算法,是一个巨大的实验任务,但是我认为进化算法的设计应该有以下思路:

构建P与F之间的关系.
若使用传统的EA算法,则P完全依赖于自己的父代,虽然在大量迭代后仍然有可能得到一代合适的参数,但是可解释性不高,完全依赖于迭代.或许可以使用差分进化算法,分别在F和P中选值.