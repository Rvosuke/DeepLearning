## 多项式分布

多项式分布是一种离散型概率分布，用于描述在进行n次独立重复实验中，每次实验的结果是k个互斥的事件中的一个的概率分布。它是二项式分布在多元分类问题上的推广。

多项式分布的概率质量函数为：

$P(X_1=x_1,X_2=x_2,...,X_k=x_k)={n\choose x_1x_2...x_k}p_1^{x_1}p_2^{x_2}...p_k^{x_k}$

其中，$x_1,x_2,...,x_k$表示各个事件发生的次数，满足$\sum\limits_{i=1}^k x_i=n$，$p_1,p_2,...,p_k$为每个事件发生的概率，满足$\sum\limits_{i=1}^k p_i=1$。

在机器学习中，多项式分布常用于文本分类等离散型数据的建模。例如，在文本分类问题中，可以将每个词的出现与否视为一个事件，那么多项式分布就可以用于描述每个文档所包含的各个词的出现情况。

在朴素贝叶斯算法中，当样本属性为离散型变量时，通常会假设其条件概率服从多项式分布。这是因为多项式分布适用于描述多个类别中每个类别出现次数的概率分布，而朴素贝叶斯算法中的条件概率正是描述在每个类别下某个属性取值的概率分布。

具体而言，对于一个给定的离散型属性$X$，其取值集合为${a_1, a_2, ..., a_n}$，假设有$K$个类别${C_1, C_2, ..., C_K}$，则在朴素贝叶斯算法中，我们假设每个类别$C_i$下属性$X$取各个值的概率服从一个多项式分布，即：

$P(X=a_j | C_i) = \theta_{ij}$，其中$j=1,2,...,n$，$i=1,2,...,K$，$\sum\limits_{j=1}^n \theta_{ij}=1$

其中$\theta_{ij}$表示在类别$C_i$下属性$X$取值为$a_j$的概率。因此，在进行朴素贝叶斯分类时，对于给定的待分类样本，我们首先要估计每个类别下属性$X$取各个值的概率$\theta_{ij}$，然后根据贝叶斯定理计算每个类别的后验概率，并选择后验概率最大的类别作为样本的分类结果。



## 均匀分布

利用似然估计估计均匀分布的参数

假设观测数据为 $x_1, x_2, ..., x_n$，且 $x_i \sim U(a,b)$，即 $x_i$ 服从区间 $(a,b)$ 上的均匀分布。我们要估计未知参数 $\theta = (a, b)$。

假设我们已知样本 $x_1, x_2, ..., x_n$，那么似然函数为：

$$L(\theta|x_1, x_2, ..., x_n) = \prod_{i=1}^n f(x_i|\theta)$$

由于 $x_i$ 的分布为均匀分布，其概率密度函数为：

$$f(x_i|\theta) = \begin{cases} \frac{1}{b-a}, a \leq x_i \leq b \ 0, \text{otherwise} \end{cases}$$

因此，似然函数为：

$$L(\theta|x_1, x_2, ..., x_n) = \begin{cases} (\frac{1}{b-a})^n, a \leq x_{(1)} \text{ and } x_{(n)} \leq b \ 0, \text{otherwise} \end{cases}$$

其中 $x_{(1)}$ 和 $x_{(n)}$ 分别为样本的最小值和最大值。

为了最大化似然函数，我们需要选择最大的可能的区间 $(a,b)$，使得其包含了所有观测数据。因此，我们可以用样本的最小值和最大值来估计参数 $\theta$，即：

$$\hat{a} = x_{(1)}, \hat{b} = x_{(n)}$$

因为 $\hat{a}$ 和 $\hat{b}$ 都是样本的函数，所以它们也被称为样本极值。这是一个无偏估计，且方差为：

$$Var(\hat{a}) = Var(\hat{b}) = \frac{(b-a)^2}{12n}$$

在实际计算中，我们可以先对样本进行排序，然后选择第一个和最后一个观测值作为估计的区间端点。