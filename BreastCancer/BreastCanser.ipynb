{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T20:38:23.830077Z",
     "start_time": "2023-04-28T20:38:22.109736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建自定义数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T20:38:27.075676Z",
     "start_time": "2023-04-28T20:38:26.322123Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "Transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    # other transforms, if needed\n",
    "])\n",
    "\n",
    "class BreastCancerSegmentationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    乳腺癌分割数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, mask_dir, transform=None, one_hot_encode=True, target_size=(256, 256)):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.one_hot_encode = one_hot_encode\n",
    "        self.target_size = target_size\n",
    "        self.img_filenames = os.listdir(img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_filenames[index]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        mask_path = os.path.join(self.mask_dir, img_name[:-4] + '_mask'+img_name[-4:])\n",
    "        # Skip .ipynb_checkpoints files\n",
    "        if img_path.endswith(\".ipynb_checkpoints\") or mask_path.endswith(\".ipynb_checkpoints\"):\n",
    "            return self.__getitem__((index + 1) % len(self))\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found at {img_path}\")\n",
    "        if mask is None:\n",
    "            raise FileNotFoundError(f\"Mask not found at {mask_path}\")\n",
    "\n",
    "        # Resize image and mask\n",
    "        image = cv2.resize(image, self.target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        mask = cv2.resize(mask, self.target_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        if self.one_hot_encode:\n",
    "            mask = one_hot_encode(mask, num_classes=3)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        mask = np.asarray(mask)   # 转换为NumPy数组\n",
    "        mask = mask.astype(np.float32)   # 变换dtype\n",
    "        mask = torch.from_numpy(mask) # 转换为Tensor\n",
    "        return image, mask\n",
    "\n",
    "class BreastCancerClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    乳腺癌分类数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.img_filenames = os.listdir(img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_filenames[index]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found at {img_path}\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "\n",
    "        # 从图像名称解析分类标签\n",
    "        if 'benign' in img_name:\n",
    "            label = 0\n",
    "        elif 'malignant' in img_name:\n",
    "            label = 1\n",
    "        elif 'normal' in img_name:\n",
    "            label = 2\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def one_hot_encode(mask, num_classes):\n",
    "    one_hot = np.zeros((mask.shape[0], mask.shape[1], num_classes), dtype=np.uint8)\n",
    "    for c in range(num_classes):\n",
    "        one_hot[..., c] = (mask == c)\n",
    "    return one_hot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用自定义数据集类加载数据并进行数据增强\n",
    "划分数据集为训练集和验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T20:38:36.909701Z",
     "start_time": "2023-04-28T20:38:34.659187Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3823,  0.3138,  0.2282,  ...,  0.2453,  0.2796,  0.1426],\n",
       "          [ 0.3309,  0.3138,  0.3994,  ...,  0.2282,  0.2624,  0.6906],\n",
       "          [ 0.5364,  0.4166,  0.3823,  ...,  0.4679,  0.5536,  0.6563],\n",
       "          ...,\n",
       "          [-1.8610, -1.8953, -1.9295,  ..., -1.7754, -1.7583, -1.8268],\n",
       "          [-1.7412, -1.7583, -1.8782,  ..., -1.8097, -1.8097, -1.8610],\n",
       "          [-1.9124, -1.9467, -1.9638,  ..., -1.8439, -1.8439, -1.8782]],\n",
       " \n",
       "         [[ 0.5203,  0.4503,  0.3627,  ...,  0.3803,  0.4153,  0.2752],\n",
       "          [ 0.4678,  0.4503,  0.5378,  ...,  0.3627,  0.3978,  0.8354],\n",
       "          [ 0.6779,  0.5553,  0.5203,  ...,  0.6078,  0.6954,  0.8004],\n",
       "          ...,\n",
       "          [-1.7731, -1.8081, -1.8431,  ..., -1.6856, -1.6681, -1.7381],\n",
       "          [-1.6506, -1.6681, -1.7906,  ..., -1.7206, -1.7206, -1.7731],\n",
       "          [-1.8256, -1.8606, -1.8782,  ..., -1.7556, -1.7556, -1.7906]],\n",
       " \n",
       "         [[ 0.7402,  0.6705,  0.5834,  ...,  0.6008,  0.6356,  0.4962],\n",
       "          [ 0.6879,  0.6705,  0.7576,  ...,  0.5834,  0.6182,  1.0539],\n",
       "          [ 0.8971,  0.7751,  0.7402,  ...,  0.8274,  0.9145,  1.0191],\n",
       "          ...,\n",
       "          [-1.5430, -1.5779, -1.6127,  ..., -1.4559, -1.4384, -1.5081],\n",
       "          [-1.4210, -1.4384, -1.5604,  ..., -1.4907, -1.4907, -1.5430],\n",
       "          [-1.5953, -1.6302, -1.6476,  ..., -1.5256, -1.5256, -1.5604]]]),\n",
       " tensor([[[1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.]],\n",
       " \n",
       "         [[1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          ...,\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.]]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=30, p=0.3),\n",
    "    A.RandomResizedCrop(height=256, width=256, scale=(0.8, 1.0), p=0.2),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "dataset = {\n",
    "    'train': BreastCancerSegmentationDataset(\"image\", \"mask\", transform=train_transform),\n",
    "    'val': BreastCancerSegmentationDataset(\"image\", \"mask\", transform=val_transform),\n",
    "    'test': BreastCancerSegmentationDataset(\"image\", \"mask\", transform=test_transform)\n",
    "}\n",
    "\n",
    "# 打印一个样本，检查数据格式和变换是否符合预期\n",
    "dataset['train'][10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T20:39:36.068721Z",
     "start_time": "2023-04-28T20:39:36.058685Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 构建训练集、验证集和测试集的 DataLoader\n",
    "train_loader = DataLoader(dataset['train'], batch_size=16, shuffle=True, num_workers=0, drop_last=True)\n",
    "val_loader = DataLoader(dataset['val'], batch_size=32, shuffle=False, num_workers=0, drop_last=True)\n",
    "test_loader = DataLoader(dataset['test'], batch_size=32, shuffle=False, num_workers=0, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化U-Net模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-28T20:43:51.593047Z",
     "start_time": "2023-04-28T20:42:17.978775Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.3580 Acc: 56418.0064 F1: 0.3979\n",
      "val Loss: 0.0817 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 126.1678s\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.0506 Acc: 64434.2817 F1: 0.5764\n",
      "val Loss: 0.0400 Acc: 64434.9001 F1: 0.7152\n",
      "Epoch time: 126.2510s\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.0351 Acc: 64430.4251 F1: 0.7430\n",
      "val Loss: 0.0281 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 128.4155s\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.0229 Acc: 64442.9744 F1: 0.7778\n",
      "val Loss: 0.0196 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 127.4309s\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.0168 Acc: 64443.9424 F1: 0.8229\n",
      "val Loss: 0.0146 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 127.5493s\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.0132 Acc: 64444.6364 F1: 0.8472\n",
      "val Loss: 0.0118 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 128.8598s\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.0107 Acc: 64444.7234 F1: 0.9167\n",
      "val Loss: 0.0098 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 127.2442s\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.0089 Acc: 64444.8988 F1: 0.9028\n",
      "val Loss: 0.0082 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 128.5314s\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.0076 Acc: 64444.9270 F1: 0.9271\n",
      "val Loss: 0.0071 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 127.7373s\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.0064 Acc: 64444.8694 F1: 0.9479\n",
      "val Loss: 0.0059 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 127.3329s\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.0056 Acc: 64444.9462 F1: 0.9583\n",
      "val Loss: 0.0053 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 129.0090s\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.0049 Acc: 64444.9577 F1: 0.9549\n",
      "val Loss: 0.0046 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 128.4620s\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.0043 Acc: 64444.9962 F1: 0.9340\n",
      "val Loss: 0.0041 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 128.7703s\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.0038 Acc: 64445.1216 F1: 0.9792\n",
      "val Loss: 0.0036 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 128.7188s\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.0035 Acc: 64445.0320 F1: 0.9792\n",
      "val Loss: 0.0033 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 127.7539s\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.0031 Acc: 64445.1088 F1: 0.9896\n",
      "val Loss: 0.0030 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 128.4505s\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.0028 Acc: 64445.1255 F1: 0.9896\n",
      "val Loss: 0.0027 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 129.0233s\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.0026 Acc: 64445.0576 F1: 0.9792\n",
      "val Loss: 0.0025 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 128.7766s\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.0023 Acc: 64445.1319 F1: 1.0000\n",
      "val Loss: 0.0022 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 128.4335s\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.0022 Acc: 64445.1280 F1: 0.9792\n",
      "val Loss: 0.0021 Acc: 64445.1319 F1: 1.0000\n",
      "Epoch time: 127.6813s\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.segmentation import fcn_resnet50\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "class UNetTrainer:\n",
    "    def __init__(self, num_classes=3, lr=1e-4):\n",
    "        self.model = self.build_model(num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def build_model(self, num_classes):\n",
    "        model = fcn_resnet50(pretrained=False, num_classes=num_classes)\n",
    "        return model\n",
    "\n",
    "    def evaluate(self, epoch, dataloader, phase):\n",
    "        if phase == \"train\":\n",
    "            self.model.train()\n",
    "        else:\n",
    "            self.model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        running_f1_score = 0.0\n",
    "\n",
    "        for images, masks in dataloader:\n",
    "            images = images.to(self.device)\n",
    "            masks = masks.to(self.device)\n",
    "\n",
    "            # 由于数据集中的mask是三维的，需要转换为二维\n",
    "            masks = torch.mean(masks, dim=3, keepdim=False).long()\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                outputs = self.model(images)['out']\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                loss = self.criterion(outputs, masks)\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(preds == masks.data)\n",
    "            running_f1_score += f1_score(masks.cpu().numpy().ravel(), preds.cpu().numpy().ravel(), average=\"macro\")\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "        epoch_f1_score = running_f1_score / len(dataloader)\n",
    "\n",
    "        print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} F1: {epoch_f1_score:.4f}\")\n",
    "\n",
    "    def train(self, num_epochs, train_loader, val_loader):\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            print(\"-\" * 10)\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            self.evaluate(epoch, train_loader, \"train\")\n",
    "            self.evaluate(epoch, val_loader, \"val\")\n",
    "\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(f\"Epoch time: {elapsed_time:.4f}s\")\n",
    "\n",
    "        print(\"Training complete\")\n",
    "\n",
    "trainer = UNetTrainer()\n",
    "trainer.train(20, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.4",
   "language": "python",
   "name": "pytorch-1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
